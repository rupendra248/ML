# -*- coding: utf-8 -*-
"""7_ML_KMeans Clustering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1lTpre61wRuu4eQpjp589eQVBJXdoc-NN
"""

import pandas as pd
from sklearn.cluster import KMeans
from sklearn import datasets
import numpy as np

iris = datasets.load_iris()
X = iris.data
y = iris.target
 
df = pd.DataFrame(X)
df.columns = ['sepal_length', 'sepal_width', 'petal_length', 'petal_width']
df['target'] = y
df.shape

#Applying Elbow Method to Know the Value of Number of Clusters
def elbow(df, column_indices, n_clusters=10, max_iter=100, tol=1e-05, init='k-means++', n_init=10, algorithm='auto'):
    import matplotlib.pyplot as plt
    inertia_values = []
    for i in range(1, n_clusters+1):
        km = KMeans(n_clusters=i, max_iter=max_iter, tol=tol, init=init, n_init=n_init, random_state=1, algorithm=algorithm)
        km.fit_predict(df.iloc[:, column_indices])
        inertia_values.append(km.inertia_)
    fig, ax = plt.subplots(figsize=(10, 7))
    plt.plot(range(1, n_clusters+1), inertia_values, color='blue')
    plt.xlabel('No. of Clusters')
    plt.ylabel('SSE / Inertia')
    plt.title('SSE / Inertia vs No. Of Clusters')
    plt.grid()
    plt.show()

elbow(df, [0, 1, 2, 3])

for i in range(len(df)):
  if df.iloc[i,4]==0:
    df.iloc[i,4]='Setosa'
  elif df.iloc[i,4]==1:
    df.iloc[i,4]='Versicolor'
  else:
    df.iloc[i,4]='Virginica'
print(df)

clusters=3

#Calculate Euclidean Distance between 2 Points
def euclidean_dis(x1, x2):
    return np.sqrt(np.sum((x1 - x2)**2))

from collections import defaultdict


class KMeans:
    
    #Initialize the datapints, cluster value and maximum iteration
    def __init__(self,data,k,max_ite):
        self.data=data
        self.k=k
        self.max_ite=max_ite
        
    def predict(self):
        centroids = defaultdict(int)
        print(centroids)
        K=self.k
        max_iter=self.max_ite
        
        for i in range(K):
            centroids[i] = self.data[i]

        r=0
        for i in range(max_iter):
            r=r+1
            classes=defaultdict(list)
            
            for key in range(K):
                classes[key]=[]
            for datapoint in self.data:
                distance=[]
                for j in range(K):

                    dis=euclidean_dis(datapoint,centroids[j])

                    distance.append(dis)
                mindis=min(distance)

                index=distance.index(mindis)
                classes[index].append(datapoint)
                old_centroid=dict(centroids)

            for t in range(K):
                class_=classes[t]
                new_centroid=np.mean(class_,axis=0)
                centroids[t]=new_centroid
            flg=1
            for t in range(K):

                a=centroids[t]
                b=old_centroid[t]
                if np.sum((a - b)/b * 100) > 0.001:
                    flg = 0
            if flg==1:
                break
        return classes,centroids

kmeans=KMeans(X,clusters,100)

classes,centroids=kmeans.predict()


for i in range(0,3):
    classes[i]=np.array(classes[i]).tolist()
    
for i in range(0,3):
    print(len(classes[i]))
print(centroids)

class0=[]
class1=[]
class2=[]

for i in range(len(iris.target)):
    if iris.target[i]==0:
        class0.append(iris.data[i])
    elif iris.target[i]==1:
        class1.append(iris.data[i])
    elif iris.target[i]==2:
        class2.append(iris.data[i])


class0=np.array(class0).tolist()
class1=np.array(class1).tolist()
class2=np.array(class2).tolist()

print (class0)
print (class1)
print (class2)