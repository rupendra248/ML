# -*- coding: utf-8 -*-
"""6_ML_2_RBF_MNIST.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1tRwzh7wOOSQttdk7xN5qb2XdlhDU0Ahi
"""

from __future__ import print_function
from sklearn.gaussian_process.kernels import PairwiseKernel
import keras
from keras.datasets import mnist
from keras.models import Sequential
from keras.layers import Dense, Dropout
import numpy as np
from sklearn.model_selection import train_test_split
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.gaussian_process import GaussianProcessRegressor

from tensorflow.keras.optimizers import RMSprop, Adam, Nadam
import tensorflow
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
import warnings
#warnings.filterwarning('ignore')

def RBF_kernel(testing_size, num_of_cluster):
  testing_size = testing_size / 100
  cluster_size = num_of_cluster
  # the data, shuffled and split between train and test sets
  (x_training, y_training), (x_testing, y_testing) = mnist.load_data()

  data_x = np.concatenate((x_training, x_testing))
  data_y = np.concatenate((y_training, y_testing))
  x_training, x_testing, y_training, y_testing = train_test_split(data_x, data_y, test_size = testing_size)

  training_samples_count = x_training.shape[0]
  testing_samples_count = x_testing.shape[0]


  x_training = x_training.reshape(training_samples_count, 784)
  x_testing = x_testing.reshape(testing_samples_count, 784)


  x_training = x_training.astype('float32')
  x_testing = x_testing.astype('float32')



  x_training /= 255
  x_testing /= 255


  y_training = tensorflow.keras.utils.to_categorical(y_training, 10)
  y_testing = tensorflow.keras.utils.to_categorical(y_testing, 10)

  #                       KMEANS to find centers
  kmeans_model = KMeans(num_of_cluster, init='random')
  kmeans_model.fit(x_training)
  centers = kmeans_model.cluster_centers_
  x = kmeans_model.predict(kmeans_model.cluster_centers_)
  x = tensorflow.keras.utils.to_categorical(x, cluster_size)
  y_trainn= kmeans_model.predict(x_training)
  y_trainn=tensorflow.keras.utils.to_categorical(y_trainn, cluster_size)
  y_testt=kmeans_model.predict(x_testing)
  y_testt= tensorflow.keras.utils.to_categorical(y_testt, cluster_size)



  kernel = PairwiseKernel(metric='polynomial')   #GPR uses the kernel to define the covariance of the training sample
  rbf_model = GaussianProcessRegressor(kernel=kernel).fit(centers, x)

  temp1 = rbf_model.predict(x_training)
  temp2 = rbf_model.predict(x_testing)


  batch_size = 128
  epochs = 10
  img_size = 28 * 28

  model = Sequential()
  model.add(Dense(img_size, activation='relu', input_shape=(cluster_size,)))
  model.add(Dropout(0.2))
  model.add(Dense(cluster_size, activation='softmax'))

  nadam=tensorflow.keras.optimizers.Nadam(lr=0.0005)
  model.compile(loss='categorical_crossentropy',
                optimizer=nadam,
                metrics=['accuracy'])


  history = model.fit(temp1, y_trainn,
                      batch_size=batch_size,
                      epochs=epochs,
                      verbose=0,
                      validation_data=(temp2, y_testt))

  #                      EVALUATE TRAINED MODEL
  score = model.evaluate(temp2, y_testt, verbose=0)
  print('Test loss:', score[0])
  print('Test accuracy:', score[1])

  plt.figure(figsize=(10,4))
  # Plot training & validation accuracy values
  plt.subplot(1,2,1)
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('Model accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Test'], loc='upper left')

  # Plot training & validation loss values
  plt.subplot(1,2,2)
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('Model loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Test'], loc='upper right')
  plt.show()
  return history, score

test_split_size_percentages = [10, 20, 30]
number_of_clusters = [5, 10, 15]

for test_size_split_percentage in tqdm(test_split_size_percentages):
  for number_of_cluster in tqdm(number_of_clusters):
    print("test_size_split_percentage", test_size_split_percentage, "%")
    print("number_of_cluster", number_of_cluster,"\n")
    history, score = RBF_kernel(test_size_split_percentage, number_of_cluster)
    print("-----------------\n\n")