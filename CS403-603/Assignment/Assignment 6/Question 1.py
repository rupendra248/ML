# -*- coding: utf-8 -*-
"""6_ML_1_RBF_iris.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1Rl1LFyZjDcO7XKpumHaNGbd4hcmBSuGH
"""

from __future__ import print_function
from sklearn.cluster import KMeans
from sklearn.decomposition import PCA
from sklearn.gaussian_process.kernels import PairwiseKernel
from sklearn.model_selection import train_test_split
from sklearn import datasets
import keras
import numpy as np


from sklearn.gaussian_process import GaussianProcessRegressor
from keras.models import Sequential
from keras.layers import Dense, Dropout
from tensorflow.keras.optimizers import RMSprop, Adam, Nadam
import tensorflow
import matplotlib.pyplot as plt
from tqdm.auto import tqdm
import warnings
warnings.filterwarnings('ignore')

def RBF_kernel(test_size, num_cluster):
  test_size = test_size/100
  size = num_cluster

  iris_dataset = datasets.load_iris() # load iris dataset
  data_x = iris_dataset.data  # Data
  data_y = iris_dataset.target  # Labels
  x_training, x_testing, y_training, y_testing = train_test_split(data_x, data_y, test_size = test_size)

  training_sample_count = x_training.shape[0]
  testing_sample_count = x_testing.shape[0]

  #                         PREPROCESSING DATA


  x_training = x_training.astype('float32')
  x_testing = x_testing.astype('float32')

  y_training = tensorflow.keras.utils.to_categorical(y_training, 10)
  y_testing = tensorflow.keras.utils.to_categorical(y_testing, 10)

  #                       KMEANS to find center
  kmeans_model = KMeans(num_cluster, init='random')   #find 10 center with kmeans on training samples
  kmeans_model.fit(x_training)
  center = kmeans_model.cluster_centers_
  x = kmeans_model.predict(kmeans_model.cluster_centers_)
  x = tensorflow.keras.utils.to_categorical(x, size)
  y_trainn= kmeans_model.predict(x_training)
  y_trainn=tensorflow.keras.utils.to_categorical(y_trainn, size)
  y_testt=kmeans_model.predict(x_testing)
  y_testt= tensorflow.keras.utils.to_categorical(y_testt, size)



  kernel = PairwiseKernel(metric='polynomial')
  rbf_model = GaussianProcessRegressor(kernel=kernel).fit(center, x)

  temp1 = rbf_model.predict(x_training)
  temp2 = rbf_model.predict(x_testing)


  size_batch = 128
  epoch = 100
  data_size = 10 * 10

  model = Sequential()
  model.add(Dense(data_size, activation='relu', input_shape=(size,)))
  model.add(Dropout(0.2))
  model.add(Dense(size, activation='softmax'))

  nadam=tensorflow.keras.optimizers.Nadam(lr=0.0005)
  model.compile(loss='categorical_crossentropy',
                optimizer=nadam,
                metrics=['accuracy'])

  history = model.fit(temp1, y_trainn,
                      batch_size=size_batch,
                      epochs=epoch,
                      verbose=0,
                      validation_data=(temp2, y_testt))

  score = model.evaluate(temp2, y_testt, verbose=0)
  print('Test loss:', score[0])
  print('Test accuracy:', score[1])

  plt.figure(figsize=(10,4))
  # Plot training & validation accuracy values
  plt.subplot(1,2,1)
  plt.plot(history.history['accuracy'])
  plt.plot(history.history['val_accuracy'])
  plt.title('Model accuracy')
  plt.ylabel('Accuracy')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Test'], loc='upper left')

  # Plot training & validation loss values
  plt.subplot(1,2,2)
  plt.plot(history.history['loss'])
  plt.plot(history.history['val_loss'])
  plt.title('Model loss')
  plt.ylabel('Loss')
  plt.xlabel('Epoch')
  plt.legend(['Train', 'Test'], loc='upper right')
  plt.show()
  return history, score

test_split_size_percentages = [10, 20, 30]
number_of_clusters = [5, 7, 9]

for test_size_split_percentage in tqdm(test_split_size_percentages):
  for no_of_cluster in tqdm(number_of_clusters):
    print("test_size_split_percentage", test_size_split_percentage, "%")
    print("no_of_cluster", no_of_cluster, "\n")
    history, score = RBF_kernel(test_size_split_percentage, no_of_cluster)
    print("-------------------------------\n\n")